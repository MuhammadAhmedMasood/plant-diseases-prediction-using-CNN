# -*- coding: utf-8 -*-
"""Plant Disease Prediction using CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dBbYQUOCZhx79BJ1XrFZwe_kTcAdopnT

Seeding process:
"""

# setting seeds for reproducibility:

import random
random.seed(0)
import numpy as np
random.seed(0)
import tensorflow as tf
tf.random.set_seed(0)

"""Importing the dependecies:"""

import os
import json
from zipfile import ZipFile
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models

"""Data Curation:

Upload the kaggle.json file:
"""

!pip install kaggle

kaggle_credentials = json.load(open("kaggle.json"))

# setup Kaggle API key as environment variables
os.environ['KAGGLE_USERNAME'] = kaggle_credentials["username"]
os.environ['KAGGLE_KEY'] = kaggle_credentials["key"]

# downloading the dataset:
!kaggle datasets download -d abdallahalidev/plantvillage-dataset

!ls

# Unzip the downloaded dataset
with ZipFile("plantvillage-dataset.zip", 'r') as zip_ref:
  zip_ref.extractall()

!ls

# printing the datasets:

print(os.listdir("plantvillage dataset")) # printing the directory ti see what we have in plantvillage dataset folder

print(len(os.listdir("plantvillage dataset/segmented"))) # finding the total number of plant diseases (classes) in the segmented folder which is 38
print(os.listdir("plantvillage dataset/segmented")[:5]) # printing the first 5 data in the segmented folder

print(len(os.listdir("plantvillage dataset/color"))) # finding the total number of plant diseases (classes) in the color folder which is 38
print(os.listdir("plantvillage dataset/color")[:5]) # printing the first 5 data in the color folder

print(len(os.listdir("plantvillage dataset/grayscale"))) # finding the total number of plant diseases (classes) in the grayscale folder which is 38
print(os.listdir("plantvillage dataset/grayscale")[:5]) # printing the first 5 data in the grayscale folder

# printing the last classes:

print(os.listdir("plantvillage dataset/segmented")[-5:]) # printing the last 5 data in the segmented folder

print(os.listdir("plantvillage dataset/color")[-5:]) # printing the last 5 data in the color folder

print(os.listdir("plantvillage dataset/grayscale")[-5:]) # printing the last 5 data in the grayscale folder

"""NUMBER OF CLASSES = 38"""

print(len(os.listdir("plantvillage dataset/color/Grape___healthy"))) # prints the number of images in class 'Grape___healthy'
print(os.listdir("plantvillage dataset/color/Grape___healthy")[:5]) # printing the first 5 images name of class 'Grape___healthy'

"""there are 423 images in the class 'Grape___helathy' in color folder"""

# reading the image and displaying it:

image_path = "plantvillage dataset/color/Grape___healthy/945a58bf-8495-4319-92c3-72dbf42116c8___Mt.N.V_HL 6082.JPG"

# read the image:

image = mpimg.imread(image_path)
print(image.shape) # printing the dimensions of the image

# displaying the image:
plt.imshow(image)
plt.axis('off') # turns off the axis
plt.show()

# checking the images in folders are already numpy arrays:

print(image)
type(image)

# Image_parameters:
img_size = 224 # selecting 224 as it's generally done so, but can go with 256 as well
batch_size = 32 # the ImageDataGenerator will prepare images in chunks of 32 for the model
                # to process during training

"""Now, let's do the train test split:"""

# Image data generator:
data_gen = ImageDataGenerator(
    rescale=1./255, # using 1. to make sure we get float
    validation_split=0.2
)

# Train Generator:

train_gen = data_gen.flow_from_directory(
    "plantvillage dataset/color",
    target_size=(img_size, img_size),
    batch_size=batch_size,
    subset="training",
    class_mode = 'categorical'
)

# Validation Generator:

validation_gen = data_gen.flow_from_directory(
    "plantvillage dataset/color",
    target_size=(img_size, img_size),
    batch_size=batch_size,
    subset="validation",
    class_mode = 'categorical'
)

"""**Convolutional Neural Network**"""

# Model Definition:
model = models.Sequential()

model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (img_size,img_size,3)))
model.add(layers.MaxPooling2D(2,2))

model.add(layers.Conv2D(6, (3,3), activation = 'relu'))
model.add(layers.MaxPooling2D(2,2))

model.add(layers.Flatten())
model.add(layers.Dense(256, activation = 'relu'))
model.add(layers.Dense(38, activation = 'softmax')) # 38 is the number of classes

# model summary
model.summary()

# compiling the model:

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

"""Model Training:"""

# training the model:
history = model.fit(
    train_gen,
    steps_per_epoch = train_gen.samples // batch_size,
    epochs = 5,
    validation_data = validation_gen,
    validation_steps = validation_gen.samples // batch_size
)

"""Model Evaluation:"""

print("Evaluating model...")
val_loss, val_accuracy = model.evaluate(validation_gen, steps = validation_gen.samples // batch_size)
print(f"Validation Accuracy: {val_accuracy*100:.2f}%")

# Plot training and validation accuracy values:

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train' ,'Test'], loc='upper left')
plt.show()

# Plot training and validation loss values:
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""**Building a predictive system**"""

# Function to load and preprocess the image using pillow

def load_and_preprocess_image(image_path, target_size = (224,224)):
    #load the image
    img = Image.open(image_path)
    # resize the image
    img = img.resize(target_size)
    # convert the image to a numpy array
    img = np.array(img)
    # add batch dimension
    img_array = np.expand_dims(img, axis = 0)
    # scale the image values to [0, 1]
    img_array = img_array.astype('float32') / 255.0 # making sure it is float
    return img_array

# function to predict the class of an image:
def predict_class(model, image_path, class_indices):
    preprocessed_image = load_and_preprocess_image(image_path)
    predictions = model.predict(preprocessed_image)
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    predicted_class_name = class_indices[predicted_class_index]
    return predicted_class_name

# Create a mapping from class indices to class names:
class_indices = {v:k for k, v in train_gen.class_indices.items()}

print(train_gen.class_indices.items())

class_indices

class_indices[5]

# saving the class names as json file
json.dump(class_indices, open('class_indices.json','w'))

# Example Usage:
# image_path = '/content/test_apple_black_rot.JPG'
# image_path = '/content/test_blueberry_healthy.jpg'
image_path = '/content/test_potato_early_blight.jpg'
predicted_class_name = predict_class(model, image_path, class_indices)

# output the result
print("Predicted Class Name:", predicted_class_name)

"""**Save the model to local**"""

model.save('planr_disease_prediction_cnn_model.h5')

for k,v in train_gen.class_indices.items():
  class_indices[v] = k
print(class_indices)

